{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Dimensionality_Reduction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMEf+0oDBEySEzR7KiOXtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloslme/handson-ml2-book/blob/main/08_Dimensionality_Reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlIgHUSZtdEx"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPjTUPLKrhSK"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"dim_reduction\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-zKTTgV0gtV"
      },
      "source": [
        "# Introduction\n",
        "Reducing dimensionality does cause some information loss (just like compressing an image to JPEG can degrade its quality), so even though it will speed up training, it may make your system perform slightly worse. It also makes your pipelines a bit more complex and thus harder to maintain. So, **if training is too slow, you should first try to train your system with the original data before considering using dimensionality reduction**. In some cases, reducing the dimensionality of the training data may filter out some noise and unnecessary details and thus result in higher performance, but in general it won’t; it will just speed up training.\n",
        "\n",
        "Reducing the number of dimensions down to two (or three) makes it possible to plot a condensed view of a high-dimensional training set on a graph and often gain some important insights by visually detecting patterns, such as clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOCesw0a299k"
      },
      "source": [
        "# The curse of dimensionality\n",
        "\n",
        "High-dimensional datasets are at risk of being very sparse: most training instances are likely to be far away from each other. This also means that a new instance will likely be far away from any training instance, making predictions much less reliable than in lower dimensions, since they will be based on much larger extrapolations. In short, **the more dimensions the training set has, the greater the risk of overfitting it**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj46P2lhuBaY"
      },
      "source": [
        "# Projection methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0HSsLy9uAhM"
      },
      "source": [
        "np.random.seed(4)\n",
        "m = 60\n",
        "w1, w2 = 0.1, 0.3\n",
        "noise = 0.1\n",
        "\n",
        "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "X = np.empty((m, 3))\n",
        "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXOyuvNUuMEW"
      },
      "source": [
        "# PCA using SVD decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9lh-uTluD13"
      },
      "source": [
        "X_centered = X - X.mean(axis=0)\n",
        "U, s, Vt = np.linalg.svd(X_centered)\n",
        "c1 = Vt.T[:, 0]\n",
        "c2 = Vt.T[:, 1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7x-M--cuPvH"
      },
      "source": [
        "m, n = X.shape\n",
        "\n",
        "S = np.zeros(X_centered.shape)\n",
        "S[:n, :n] = np.diag(s)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_VWDoFMuRjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc99e8b-de80-4a4c-ff87-5eb5b1070766"
      },
      "source": [
        "np.allclose(X_centered, U.dot(S).dot(Vt))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNCxfgYuTFN"
      },
      "source": [
        "W2 = Vt.T[:, :2]\n",
        "X2D = X_centered.dot(W2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq5Q2OFhuU6i"
      },
      "source": [
        "X2D_using_svd = X2D"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxWj61wK4Y8j"
      },
      "source": [
        "# PCA using Scikit-Learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGXYgxTUuW4t"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X2D = pca.fit_transform(X)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7eoSB9n4goN",
        "outputId": "acf5b322-e665-45f5-cd1e-7576a53a9bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X2D[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.26203346,  0.42067648],\n",
              "       [-0.08001485, -0.35272239],\n",
              "       [ 1.17545763,  0.36085729],\n",
              "       [ 0.89305601, -0.30862856],\n",
              "       [ 0.73016287, -0.25404049]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Fxxlv_4m_F",
        "outputId": "78068329-fb13-4467-9cd0-2d6a6f23026a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X2D_using_svd[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.26203346, -0.42067648],\n",
              "       [ 0.08001485,  0.35272239],\n",
              "       [-1.17545763, -0.36085729],\n",
              "       [-0.89305601,  0.30862856],\n",
              "       [-0.73016287,  0.25404049]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l32SJdie4o-1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}